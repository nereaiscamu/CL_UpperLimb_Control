Notes Experiments:

Experiment 1: Datasets in order from baseline to offset perturbation. All data used, each dataset divided into 2 subsets (only first half and second half).
Experiment 2: Same but shuffled data.
Experiment 3: Same as 2, not interesting.
Experiment 4: None.
Experiment 5:Shuffled data, different order than experiment 2.
Experiment 6:Shuffled data, different order than experiment 2 and 5.
# here modified generate_sim_data_v2 to put task 1 to be mix of removed and shuffled neurons and gain and offset to 60% instead of 50. 
#Changed shuffled to 50% instead of 60.
Experiment 7: Generate dataset of 1 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at -0.1.
Experiment 8: Generate dataset of 5 trial each and see if the detector is still able to learn and if the threshold approach works.Threshold at 0.2.
Experiment 9: Generate dataset of 10 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.4.
Experiment 10: Generate dataset of 15 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.5.
Experiment 11: Generate dataset of 20 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.6.
Experiment 12: Generate dataset of 25 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.65.
Experiment 13: Generate dataset of 30 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.7.
Experiment 14: Generate dataset of 35 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.75.
Experiment 15: Generate dataset of 40 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.8.
Experiment 16: Generate dataset of 45 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.8.
Experiment 17: Generate dataset of 50 trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.8.
Experiment 18: Generate dataset of all trials each and see if the detector is still able to learn and if the threshold approach works. Threshold at 0.8.
### Now trying everything with the same hyperparameters
Experiment 19: Generate dataset of 1 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 20: Generate dataset of 5 trial each and see if the detector is still able to learn and if the threshold approach works.
Experiment 21: Generate dataset of 10 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 22: Generate dataset of 15 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 23: Generate dataset of 20 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 24: Generate dataset of 25 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 25: Generate dataset of 30 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 26: Generate dataset of 35 trials each and see if the detector is still able to learn and if the threshold approach works. 
Experiment 51: Use dataset of trial 47. The beta value for the regularizer is 0.5 here. Need to check if the beta change can avoid catastrophic forgetting of the first task.
Experiment 63: Use dataset 60, with all trials included and only positive values. Here the beta value for the first task was changed to 100. 
Experiment 64: Use dataset 60, with all trials included and only positive values. Here corrected bug, now firts task retained. 
Experiment 65: Same as 64 but we will only use regularization on the tasks which do not have CL reg (so when calc_reg = 0)
Experiment66: Use sorted datasets from data 60. No regularization within tasks, only the CL. 
Experiment67: Use sorted datasets from data 60. Here regularization within tasks, plus the CL. 
Experiment68_control: Use sorted datasets from data 60. Here regularization within tasks, not CL. Here the difference is that we removed the hyperfan init to see if that was making the hypernetwork learn faster. 
Experiment69: Use sorted datasets from data 60. Here regularization within tasks, plus the CL. Changed the architecture of the hypernetwork to see the difference (from 1 hidden layer size 13, to 2 hidden layers size 100 (default from hypnettorch))
Experiment70: Use sorted datasets from data 60. Here regularization within tasks, plus the CL. Changed the architecture of the hypernetwork to see the difference (from 1 hidden layer size 13, to 2 hidden layers size 100 (default from hypnettorch)). Here we also increase the embedding size from 8 to 24. 
Experiment73: Same as 71, but here in the script the alpha reg for the first trained task in the hnet is 0.01, while for the rest it is 1e-5. It should increase the impact of CL in late tasks and avoid overfitting on the first task. 