{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nerea/anaconda3/envs/sinthlab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.helpers import *\n",
    "from src.visualize import *\n",
    "from src.trainer import *\n",
    "from Models.models import *\n",
    "from Models.SimpleRNN_NC import SimpleRNN_NC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import *\n",
    "from copy import deepcopy\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert between numpy arrays and tensors\n",
    "to_t = lambda array: torch.tensor(array, device='cpu', dtype=dtype)  #device\n",
    "to_t_eval =  lambda array: torch.tensor(array, device='cuda', dtype=dtype)  #device\n",
    "from_t = lambda tensor: tensor.to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Data/Processed_Data/Tidy_Sansa_13_04.pkl'\n",
    "\n",
    "with open(data_path, 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = df.loc[df.type == 'BASELINE'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df = df.loc[df.type == 'TONIC'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test trials  4\n",
      "Val trials 3\n",
      "Test trials  8\n",
      "Val trials 7\n",
      "We are testing the optimization method on fold  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb8d9d8ddd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_b, y_train_b, X_val_b, y_val_b, X_test_b, y_test_b, info_train_b, info_val_b, info_test_b = train_test_split(baseline_df, train_variable = 'both_rates', \n",
    "                                                                                                   target_variable = 'target_pos', num_folds = 5)\n",
    "X_train_s, y_train_s, X_val_s, y_val_s, X_test_s, y_test_s, info_train_s, info_val_s, info_test_s = train_test_split(stim_df, train_variable = 'both_rates', \n",
    "                                                                                                   target_variable = 'target_pos', num_folds = 5)\n",
    "# Test one of the folds first\n",
    "fold_num = 'fold1'\n",
    "fold = 1\n",
    "\n",
    "\n",
    "\n",
    "print('We are testing the optimization method on fold ', fold)\n",
    "\n",
    "def input_mats(x,y, seq_length = 75):\n",
    "    x = x[fold_num]\n",
    "    y = y[fold_num]\n",
    "    x = x.reshape(x.shape[0] // seq_length, seq_length, x.shape[1])  \n",
    "    y = y.reshape(y.shape[0] // seq_length, seq_length, y.shape[1])  \n",
    "    return x,y\n",
    "\n",
    "x_train_base, y_train_base = input_mats(X_train_b, y_train_b)\n",
    "x_train_stim, y_train_stim = input_mats(X_train_s, y_train_s)\n",
    "\n",
    "x_val_base, y_val_base = input_mats(X_val_b, y_val_b)\n",
    "x_val_stim, y_val_stim = input_mats(X_val_s, y_val_s)\n",
    "\n",
    "x_test_base, y_test_base = input_mats(X_test_b, y_test_b)\n",
    "x_test_stim, y_test_stim = input_mats(X_test_s, y_test_s)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_dict(param_names, param_values):\n",
    "    s_d = {}\n",
    "    for n,v in zip(param_names, param_values):\n",
    "        s_d[n] = v\n",
    "    return s_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class dev_model(nn.Module):\n",
    "    def __init__(self,  hnet_output, \n",
    "                    num_features=124, \n",
    "                    hidden_size= 3, #was 128\n",
    "                    #initial_offset = -2,\n",
    "                    num_layers = 2, \n",
    "                    input_size = 50,\n",
    "                    out_dims = 6, \n",
    "                    dropout_1 = 0.3, \n",
    "                    dropout_2 = 0.3, \n",
    "                    bias = True,\n",
    "                    LSTM_ = False):\n",
    "        \n",
    "        super(dev_model, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hnet_output = hnet_output\n",
    "        self.bias = bias\n",
    "        self.out_features = out_dims\n",
    "        self.LSTM_ = LSTM_\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p= dropout_1) #trial.suggest_float('dropout_1', 0.1, 0.9)\n",
    "        self.dropout2 = nn.Dropout(p= dropout_2)\n",
    "\n",
    "        # Define recurrent layer\n",
    "        self.rnn = nn.RNN(self.input_size, self.hidden_size, self.num_layers, self.bias, batch_first = True, bidirectional = False)\n",
    "        names_p = [name for name, _ in self.rnn.named_parameters()]\n",
    "        self.hnet_output_dict = create_state_dict(names_p,hnet_output[4:] )\n",
    "\n",
    "        # Initialize CustomRNN\n",
    "        if self.LSTM_:\n",
    "            self.rnn = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, self.bias, batch_first = True, bidirectional = False)\n",
    "            names_p = [name for name, _ in self.rnn.named_parameters()]\n",
    "            self.hnet_output_dict = create_state_dict(names_p,hnet_output[4:] )            \n",
    "\n",
    "    def forward(self, x, hx=None):\n",
    "        x = F.linear(x, self.hnet_output[0], bias=self.hnet_output[1])\n",
    "        x = self.dropout1(x)\n",
    "        # Forward pass\n",
    "        if hx is None:\n",
    "            if self.LSTM_:\n",
    "                h0 = torch.randn(self.num_layers, x.size(0), self.hidden_size, device=x.device) * 0.1\n",
    "                c0 = torch.randn(self.num_layers, x.size(0), self.hidden_size, device=x.device) *0.1 # Initialize cell state\n",
    "                hx = (h0, c0)\n",
    "            else:\n",
    "                hx = torch.randn(self.num_layers, x.size(0), self.hidden_size, device=x.device) * 0.1\n",
    "\n",
    "        # Perform RNN operation\n",
    "        x, _  = torch.func.functional_call(self.rnn, self.hnet_output_dict, (x, hx))\n",
    "        #self.lstm.flatten_parameters()  # Add this line to flatten parameters\n",
    "        #x, _ = self.lstm(x) \n",
    "        x = self.dropout2(x)\n",
    "        output =  F.linear(x, self.hnet_output[2], bias=self.hnet_output[3])\n",
    "        # Apply sigmoid activation function\n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        return output.squeeze() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 20\n",
    "input_size = 40\n",
    "output_size = 3\n",
    "input_features = 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_ = False\n",
    "param_shapes = [[input_size, input_features], [input_size], [output_size, hidden_size], [output_size], [hidden_size, input_size], [hidden_size, hidden_size], [hidden_size], [hidden_size]]\n",
    "\n",
    "if LSTM_ == True:\n",
    "    param_shapes = [[input_size, input_features], [input_size], [output_size, hidden_size], [output_size], [hidden_size*4, input_size], [hidden_size*4, hidden_size], [hidden_size*4], [hidden_size*4]]\n",
    "#param_shapes = [[50, 127], [50], [3, 22], [3], [22, 50], [22, 22], [22],[22]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created MLP Hypernet.\n",
      "Hypernetwork with 199399 weights and 6423 outputs (compression ratio: 31.04).\n",
      "The network consists of 199383 unconditional weights (199383 internally maintained) and 16 conditional weights (16 internally maintained).\n"
     ]
    }
   ],
   "source": [
    "from hypnettorch.hnets import HMLP\n",
    "\n",
    "num_conditions = 2\n",
    "size_task_embedding = 8\n",
    "\n",
    "hnet = HMLP(param_shapes, uncond_in_size=0,\n",
    "             cond_in_size=size_task_embedding,\n",
    "            layers=[30], \n",
    "            num_cond_embs=num_conditions).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim_output = y_train_base.shape[2]\n",
    "num_features = x_train_base.shape[2]\n",
    "\n",
    "# Hyperparameters LSTM class\n",
    "num_layers = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in hnet.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_test = hnet(cond_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dev_model(num_features= num_features, hnet_output = w_test,  hidden_size = hidden_size,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.1, dropout_2= 0.1, LSTM_ = False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Set up the optimizer with the specified learning rate\\noptimizer = torch.optim.Adam(hnet.internal_params, lr= 0.001)\\n\\n# Set up a learning rate scheduler\\nscheduler = lr_scheduler.StepLR(optimizer, \\n                                step_size=10, \\n                                gamma=0.9)\\n\\n# Keep track of the best model\\'s parameters and loss\\nbest_model_wts = deepcopy(hnet.state_dict())\\nbest_loss = 1e8\\n\\n# Enable anomaly detection for debugging\\ntorch.autograd.set_detect_anomaly(True)\\n\\n# Track the train and validation loss\\ntrain_losses = []\\nval_losses = []\\n# Counters for early stopping\\nnot_increased = 0\\nend_train = 0\\n\\n\\nsequence_length_LSTM = 10\\nbatch_size_train = batch_size_val = 25\\n\\n\\n# Reshape data for the LSTM\\ntrain_dataset_baseline = SequenceDataset(\\ny_train_base,    x_train_base,    sequence_length=sequence_length_LSTM)\\n\\ntrain_dataset_stim = SequenceDataset(\\ny_train_stim,    x_train_stim,    sequence_length=sequence_length_LSTM)\\n\\nval_dataset_baseline = SequenceDataset(\\ny_val_base,    x_val_base,    sequence_length=sequence_length_LSTM)\\n\\nval_dataset_stim = SequenceDataset(\\ny_val_stim,    x_val_stim,    sequence_length=sequence_length_LSTM)\\n\\nloader_train_b = data.DataLoader(train_dataset_baseline, batch_size=batch_size_train, shuffle=True)\\nloader_train_s = data.DataLoader(train_dataset_stim, batch_size=batch_size_train, shuffle=True)\\n\\nloader_val_b = data.DataLoader(val_dataset_baseline, batch_size=batch_size_val, shuffle=True)\\nloader_val_s = data.DataLoader(val_dataset_stim, batch_size=batch_size_val, shuffle=True)\\n\\n\\n\\n# Loop through epochs\\nfor epoch in np.arange(25):\\n    for phase in [\\'train\\', \\'val\\']:\\n        # set model to train/validation as appropriate\\n        if phase == \\'train\\':\\n            model.train()\\n            loaders = zip(loader_train_b, loader_train_s)\\n        else:\\n            model.eval()\\n            loaders = zip(loader_val_b, loader_val_s)\\n\\n        # Initialize variables to track loss and batch size\\n        running_loss = 0\\n        running_size = 0      \\n\\n        # Initialize h0 and c0 outside the model\\n        h0 = torch.zeros(num_layers, batch_size_train, model.hidden_size).to(device)\\n        c0 = torch.zeros(num_layers, batch_size_train, model.hidden_size).to(device)\\n        hx = (h0, c0)  \\n\\n        # Iterate over batches in the loader\\n        for data_b, data_s in loaders:\\n\\n            # Define data for this batch\\n            x_b = data_b[0].to(\\'cuda\\')\\n            y_b = data_b[1].to(\\'cuda\\')\\n            x_s = data_s[0].to(\\'cuda\\')\\n            y_s = data_s[1].to(\\'cuda\\')\\n\\n            if phase == \"train\":\\n                    with torch.set_grad_enabled(True):\\n                        optimizer.zero_grad()\\n\\n                        # Compute BASELINE loss.\\n                        W_base = hnet(cond_id=0)  \\n       \\n                        model = dev_model(num_features= num_features, hnet_output = W_base,  hidden_size = hidden_units,\\n                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \\n                            dropout_1= 0.2, dropout_2= 0.2).to(device)\\n                                    \\n                        base_P = model(x_b, hx)\\n                   \\n                        loss_base = huber_loss(base_P, y_b, delta = 8)\\n                        \\n                        loss_base.backward()\\n                        #print(hnet.unconditional_params[-1])\\n                        # Iterate over parameters of hnet and compute gradients\\n                        # Iterate over parameters of hnet and compute gradients\\n                       \\n                        for name, param in hnet.named_parameters():\\n                            if param.requires_grad:\\n                                print(\"Gradient for {}: {}\".format(name, param.grad))\\n\\n                        \\n                        optimizer.step()\\n            else:\\n                # just compute the loss in validation phase\\n                W_base = hnet(cond_id=0)\\n                model = dev_model(num_features= num_features, hnet_output = W_base,  hidden_size = hidden_units,\\n                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \\n                            dropout_1= 0.2, dropout_2= 0.2).to(device)\\n                                    \\n                base_P = model(x_b, hx)\\n                \\n                loss_base = huber_loss(base_P, y_b, delta = 8)\\n\\n               \\n            # Ensure the loss is finite\\n            assert torch.isfinite(loss_base)\\n            assert torch.isfinite(loss_base)\\n            running_loss += loss_base.item()\\n            running_size += 1\\n\\n        # compute the train/validation loss and update the best\\n        # model parameters if this is the lowest validation loss yet\\n        running_loss /= running_size\\n        if phase == \"train\":\\n            train_losses.append(running_loss)\\n        else:\\n            val_losses.append(running_loss)\\n            # Update best model parameters if validation loss improves\\n            if running_loss < best_loss:\\n                best_loss = running_loss\\n                best_model_wts = deepcopy(model.state_dict())\\n                not_increased = 0\\n            else:\\n                # Perform early stopping if validation loss doesn\\'t improve\\n                if epoch > 10:\\n                    not_increased += 1\\n                    # print(\\'Not increased : {}/5\\'.format(not_increased))\\n                    if not_increased == 5:\\n                        print(\\'Decrease LR\\')\\n                        for g in optimizer.param_groups:\\n                            g[\\'lr\\'] = g[\\'lr\\'] / 2\\n                        not_increased = 0\\n                        end_train += 1\\n                    \\n                    if end_train == 2:\\n                        model.load_state_dict(best_model_wts)\\n                       \\n    scheduler.step()\\n    \\n    print(\"Epoch {:03} Train {:.4f} Val {:.4f}\".format(epoch, train_losses[-1], val_losses[-1])) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Set up the optimizer with the specified learning rate\n",
    "optimizer = torch.optim.Adam(hnet.internal_params, lr= 0.001)\n",
    "\n",
    "# Set up a learning rate scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, \n",
    "                                step_size=10, \n",
    "                                gamma=0.9)\n",
    "\n",
    "# Keep track of the best model's parameters and loss\n",
    "best_model_wts = deepcopy(hnet.state_dict())\n",
    "best_loss = 1e8\n",
    "\n",
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Track the train and validation loss\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Counters for early stopping\n",
    "not_increased = 0\n",
    "end_train = 0\n",
    "\n",
    "\n",
    "sequence_length_LSTM = 10\n",
    "batch_size_train = batch_size_val = 25\n",
    "\n",
    "\n",
    "# Reshape data for the LSTM\n",
    "train_dataset_baseline = SequenceDataset(\n",
    "y_train_base,    x_train_base,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "train_dataset_stim = SequenceDataset(\n",
    "y_train_stim,    x_train_stim,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "val_dataset_baseline = SequenceDataset(\n",
    "y_val_base,    x_val_base,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "val_dataset_stim = SequenceDataset(\n",
    "y_val_stim,    x_val_stim,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "loader_train_b = data.DataLoader(train_dataset_baseline, batch_size=batch_size_train, shuffle=True)\n",
    "loader_train_s = data.DataLoader(train_dataset_stim, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "loader_val_b = data.DataLoader(val_dataset_baseline, batch_size=batch_size_val, shuffle=True)\n",
    "loader_val_s = data.DataLoader(val_dataset_stim, batch_size=batch_size_val, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Loop through epochs\n",
    "for epoch in np.arange(25):\n",
    "    for phase in ['train', 'val']:\n",
    "        # set model to train/validation as appropriate\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "            loaders = zip(loader_train_b, loader_train_s)\n",
    "        else:\n",
    "            model.eval()\n",
    "            loaders = zip(loader_val_b, loader_val_s)\n",
    "\n",
    "        # Initialize variables to track loss and batch size\n",
    "        running_loss = 0\n",
    "        running_size = 0      \n",
    "\n",
    "        # Initialize h0 and c0 outside the model\n",
    "        h0 = torch.zeros(num_layers, batch_size_train, model.hidden_size).to(device)\n",
    "        c0 = torch.zeros(num_layers, batch_size_train, model.hidden_size).to(device)\n",
    "        hx = (h0, c0)  \n",
    "\n",
    "        # Iterate over batches in the loader\n",
    "        for data_b, data_s in loaders:\n",
    "\n",
    "            # Define data for this batch\n",
    "            x_b = data_b[0].to('cuda')\n",
    "            y_b = data_b[1].to('cuda')\n",
    "            x_s = data_s[0].to('cuda')\n",
    "            y_s = data_s[1].to('cuda')\n",
    "\n",
    "            if phase == \"train\":\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # Compute BASELINE loss.\n",
    "                        W_base = hnet(cond_id=0)  \n",
    "       \n",
    "                        model = dev_model(num_features= num_features, hnet_output = W_base,  hidden_size = hidden_units,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.2, dropout_2= 0.2).to(device)\n",
    "                                    \n",
    "                        base_P = model(x_b, hx)\n",
    "                   \n",
    "                        loss_base = huber_loss(base_P, y_b, delta = 8)\n",
    "                        \n",
    "                        loss_base.backward()\n",
    "                        #print(hnet.unconditional_params[-1])\n",
    "                        # Iterate over parameters of hnet and compute gradients\n",
    "                        # Iterate over parameters of hnet and compute gradients\n",
    "                       \n",
    "                        for name, param in hnet.named_parameters():\n",
    "                            if param.requires_grad:\n",
    "                                print(\"Gradient for {}: {}\".format(name, param.grad))\n",
    "\n",
    "                        \n",
    "                        optimizer.step()\n",
    "            else:\n",
    "                # just compute the loss in validation phase\n",
    "                W_base = hnet(cond_id=0)\n",
    "                model = dev_model(num_features= num_features, hnet_output = W_base,  hidden_size = hidden_units,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.2, dropout_2= 0.2).to(device)\n",
    "                                    \n",
    "                base_P = model(x_b, hx)\n",
    "                \n",
    "                loss_base = huber_loss(base_P, y_b, delta = 8)\n",
    "\n",
    "               \n",
    "            # Ensure the loss is finite\n",
    "            assert torch.isfinite(loss_base)\n",
    "            assert torch.isfinite(loss_base)\n",
    "            running_loss += loss_base.item()\n",
    "            running_size += 1\n",
    "\n",
    "        # compute the train/validation loss and update the best\n",
    "        # model parameters if this is the lowest validation loss yet\n",
    "        running_loss /= running_size\n",
    "        if phase == \"train\":\n",
    "            train_losses.append(running_loss)\n",
    "        else:\n",
    "            val_losses.append(running_loss)\n",
    "            # Update best model parameters if validation loss improves\n",
    "            if running_loss < best_loss:\n",
    "                best_loss = running_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                not_increased = 0\n",
    "            else:\n",
    "                # Perform early stopping if validation loss doesn't improve\n",
    "                if epoch > 10:\n",
    "                    not_increased += 1\n",
    "                    # print('Not increased : {}/5'.format(not_increased))\n",
    "                    if not_increased == 5:\n",
    "                        print('Decrease LR')\n",
    "                        for g in optimizer.param_groups:\n",
    "                            g['lr'] = g['lr'] / 2\n",
    "                        not_increased = 0\n",
    "                        end_train += 1\n",
    "                    \n",
    "                    if end_train == 2:\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                       \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"Epoch {:03} Train {:.4f} Val {:.4f}\".format(epoch, train_losses[-1], val_losses[-1])) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_test(weights, alpha, l1_ratio):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement an L1-L2 penalty on the norm of the model weights.\n",
    "\n",
    "    model: MLP\n",
    "    alpha: scaling parameter for the regularization.\n",
    "    l1_ratio: mixing parameter between L1 and L2 loss.\n",
    "\n",
    "    Returns:\n",
    "    reg: regularization term\n",
    "    \"\"\"\n",
    "    l1_loss = 0\n",
    "    l2_loss = 0\n",
    "\n",
    "    # Accumulate L1 and L2 losses for weight matrices in the model\n",
    "    for weight_tensor in weights[2]:\n",
    "        l1_loss += torch.sum(torch.abs(weight_tensor))\n",
    "        l2_loss += torch.sum(weight_tensor.pow(2))\n",
    "\n",
    "    reg = l1_ratio * l1_loss + (1 - l1_ratio) * l2_loss\n",
    "\n",
    "    reg = alpha * reg\n",
    "\n",
    "    # Accumulate L1 and L2 losses for weight matrices in the model\n",
    "    for weight_tensor in weights:\n",
    "        l1_loss += torch.sum(torch.abs(weight_tensor))\n",
    "        l2_loss += torch.sum(weight_tensor.pow(2))\n",
    "\n",
    "    reg_item = l1_ratio * l1_loss + (1 - l1_ratio) * l2_loss\n",
    "\n",
    "    reg_item = alpha * reg_item\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self._param_shapes_meta.append({\n",
    "        'name': 'bias' if is_bias else 'weight',\n",
    "        'index': -1 if self._no_weights else \\\n",
    "            len(self._weights)-1,\n",
    "        'layer': i * 2 + num_prev_layers, # Odd numbers\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.param_shapes_meta = [{\n",
    "    'name': 'weight',\n",
    "    'index':0,\n",
    "    'layer': 0\n",
    "}, \n",
    "{\n",
    "    'name': 'bias',\n",
    "    'index':1,\n",
    "    'layer': 0\n",
    "}, \n",
    "{\n",
    "    'name': 'weight',\n",
    "    'index':2,\n",
    "    'layer': 2\n",
    "}, \n",
    "{\n",
    "    'name': 'bias',\n",
    "    'index':3,\n",
    "    'layer': 2\n",
    "}, \n",
    "{\n",
    "    'name': 'weight',\n",
    "    'index':4,\n",
    "    'layer': 1\n",
    "}, \n",
    "{\n",
    "    'name': 'weight',\n",
    "    'index':5,\n",
    "    'layer': 1\n",
    "}, \n",
    "{\n",
    "    'name': 'bias',\n",
    "    'index':6,\n",
    "    'layer': 1\n",
    "}, \n",
    "{\n",
    "    'name': 'bias',\n",
    "    'index':7,\n",
    "    'layer': 1\n",
    "}, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hypernet(model, hnet,y_train_base, x_train_base,\n",
    "                y_train_stim,  x_train_stim,\n",
    "                y_val_base,  x_val_base,\n",
    "                y_val_stim,    x_val_stim,\n",
    "                lr=0.0001,\n",
    "                lr_step_size=10,\n",
    "                lr_gamma=0.9,\n",
    "                sequence_length_LSTM=10,\n",
    "                batch_size_train = 25,\n",
    "                batch_size_val = 25,\n",
    "                num_epochs=1000, \n",
    "                delta = 8,                 \n",
    "                regularizer=None,\n",
    "                l1_ratio = 0.5,\n",
    "                alpha = 1e-5,     \n",
    "                early_stop = 5,\n",
    "                chunks = False\n",
    "                \n",
    "                ):\n",
    "\n",
    "    \n",
    "    # Initialize the hypernetwork\n",
    "\n",
    "    # --> this was only when using th models from hypnettorch\n",
    "    \"\"\"     if chunks:\n",
    "         hnet.apply_chunked_hyperfan_init(mnet = model)\n",
    "    else: \n",
    "         hnet.apply_hyperfan_init(mnet=model) \"\"\"\n",
    "    hnet.apply_hyperfan_init(mnet=model)\n",
    "\n",
    "    # Set up the optimizer with the specified learning rate\n",
    "    optimizer = torch.optim.Adam(hnet.internal_params, lr=lr)\n",
    "\n",
    "    # Set up a learning rate scheduler\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, \n",
    "                                    step_size=lr_step_size, \n",
    "                                    gamma=lr_gamma)\n",
    "    \n",
    "    # Keep track of the best model's parameters and loss\n",
    "    best_model_wts = deepcopy(model.state_dict())\n",
    "    best_loss = 1e8\n",
    "\n",
    "    # Enable anomaly detection for debugging\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "    # Track the train and validation loss\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # Counters for early stopping\n",
    "    not_increased = 0\n",
    "    end_train = 0\n",
    "    \n",
    "    # Reshape data for the LSTM\n",
    "    train_dataset_baseline = SequenceDataset(\n",
    "    y_train_base,    x_train_base,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "    train_dataset_stim = SequenceDataset(\n",
    "    y_train_stim,    x_train_stim,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "    val_dataset_baseline = SequenceDataset(\n",
    "    y_val_base,    x_val_base,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "    val_dataset_stim = SequenceDataset(\n",
    "    y_val_stim,    x_val_stim,    sequence_length=sequence_length_LSTM)\n",
    "\n",
    "    loader_train_b = data.DataLoader(train_dataset_baseline, batch_size=batch_size_train, shuffle=True)\n",
    "    loader_train_s = data.DataLoader(train_dataset_stim, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "    loader_val_b = data.DataLoader(val_dataset_baseline, batch_size=batch_size_val, shuffle=True)\n",
    "    loader_val_s = data.DataLoader(val_dataset_stim, batch_size=batch_size_val, shuffle=True)\n",
    "\n",
    "    # Initialize h0 and c0 outside the model\n",
    "    if LSTM_ == True:\n",
    "\n",
    "        h0 = torch.randn(num_layers, batch_size_train, hidden_size, device=device) * 0.1\n",
    "        c0 = torch.randn(num_layers, batch_size_train, hidden_size, device=device) *0.1 # Initialize cell state\n",
    "        hx = (h0, c0) \n",
    "    else:\n",
    "        hx = torch.randn(num_layers, batch_size_train, hidden_size, device=device) * 0.1\n",
    "    # Loop through epochs\n",
    "    for epoch in np.arange(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            # set model to train/validation as appropriate\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loaders = zip(loader_train_b, loader_train_s)\n",
    "            else:\n",
    "                model.eval()\n",
    "                loaders = zip(loader_val_b, loader_val_s)\n",
    "\n",
    "            # Initialize variables to track loss and batch size\n",
    "            running_loss = 0\n",
    "            running_size = 0        \n",
    "\n",
    "            # Iterate over batches in the loader\n",
    "            for data_b, data_s in loaders:\n",
    "\n",
    "                # Define data for this batch\n",
    "                x_b = data_b[0].to('cuda')\n",
    "                y_b = data_b[1].to('cuda')\n",
    "                x_s = data_s[0].to('cuda')\n",
    "                y_s = data_s[1].to('cuda')\n",
    "               \n",
    "                if phase == \"train\":\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # Compute BASELINE loss.\n",
    "                        W_base = hnet(cond_id=0)\n",
    "                        model = dev_model(num_features= num_features, hnet_output = W_base,  hidden_size = hidden_size,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.2, dropout_2= 0.2, LSTM_ = False).to(device)\n",
    "                                    \n",
    "                        base_P = model(x_b, hx)\n",
    "                        \n",
    "                        loss_base = huber_loss(base_P, y_b, delta = delta)\n",
    "                        \n",
    "                        \n",
    "                        # Compute STIMULATION loss.\n",
    "                        W_stim = hnet(cond_id=1)\n",
    "                        model = dev_model(num_features= num_features, hnet_output = W_stim,  hidden_size = hidden_size,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.2, dropout_2= 0.2, LSTM_ = False).to(device)          \n",
    "                        stim_P = model(x_b, hx)\n",
    "                        loss_stim = huber_loss(stim_P, y_s, delta = delta)\n",
    "                        \n",
    "                        # Combine loss for 2 tasks\n",
    "                        loss_t = loss_base + loss_stim    #only for printing\n",
    "\n",
    "                        # Add regularization to the loss in the training phase\n",
    "                        if regularizer is not None:\n",
    "                            loss_stim_reg = loss_stim + reg_test(W_stim, l1_ratio, alpha)\n",
    "                            loss_base_reg = loss_base + reg_test(W_base, l1_ratio, alpha)\n",
    "                            # Combine loss for 2 tasks\n",
    "                            loss_t_r = loss_base_reg + loss_stim_reg\n",
    "\n",
    "                        else:               \n",
    "                            loss_t_r = loss_t \n",
    "                        \n",
    "                        \n",
    "\n",
    "                        # Compute gradients and perform an optimization step\n",
    "                        loss_t_r.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                else:\n",
    "                    # just compute the loss in validation phase\n",
    "                    W_base = hnet(cond_id=0)\n",
    "                    model = dev_model(num_features= num_features, hnet_output = W_base,  hidden_size = hidden_size,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.2, dropout_2= 0.2, LSTM_ = False).to(device)          \n",
    "                    base_P = model(x_b, hx)\n",
    "                    loss_base = huber_loss(base_P, y_b, delta = delta)\n",
    "\n",
    "                    W_stim = hnet(cond_id=1)\n",
    "                    model = dev_model(num_features= num_features, hnet_output = W_stim,  hidden_size = hidden_size,\n",
    "                            num_layers= num_layers, input_size = input_size,out_dims=num_dim_output,  \n",
    "                            dropout_1= 0.2, dropout_2= 0.2, LSTM_ = False).to(device)          \n",
    "                    stim_P = model(x_b, hx)\n",
    "                    loss_stim = huber_loss(stim_P, y_s, delta = delta)\n",
    "\n",
    "                    loss_t = loss_base + loss_stim\n",
    "\n",
    "                # Ensure the loss is finite\n",
    "                assert torch.isfinite(loss_t)\n",
    "                assert torch.isfinite(loss_t_r)\n",
    "                running_loss += loss_t.item()\n",
    "                running_size += 1\n",
    "\n",
    "            # compute the train/validation loss and update the best\n",
    "            # model parameters if this is the lowest validation loss yet\n",
    "            running_loss /= running_size\n",
    "            if phase == \"train\":\n",
    "                train_losses.append(running_loss)\n",
    "            else:\n",
    "                val_losses.append(running_loss)\n",
    "                # Update best model parameters if validation loss improves\n",
    "                if running_loss < best_loss:\n",
    "                    best_loss = running_loss\n",
    "                    best_model_wts = deepcopy(model.state_dict())\n",
    "                    not_increased = 0\n",
    "                else:\n",
    "                    # Perform early stopping if validation loss doesn't improve\n",
    "                    if epoch > 10:\n",
    "                        not_increased += 1\n",
    "                        # print('Not increased : {}/5'.format(not_increased))\n",
    "                        if not_increased == early_stop:\n",
    "                            print('Decrease LR')\n",
    "                            for g in optimizer.param_groups:\n",
    "                                g['lr'] = g['lr'] / 2\n",
    "                            not_increased = 0\n",
    "                            end_train += 1\n",
    "                        \n",
    "                        if end_train == 2:\n",
    "                            model.load_state_dict(best_model_wts)\n",
    "                            return np.array(train_losses), np.array(val_losses), W_base, W_stim\n",
    "\n",
    "        # Update learning rate with the scheduler\n",
    "        scheduler.step()\n",
    "        print(\"Epoch {:03} Train {:.4f} Val {:.4f}\".format(epoch, train_losses[-1], val_losses[-1]))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return np.array(train_losses), np.array(val_losses), W_base, W_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t_losses, val_losses, W_base, W_stim \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_hypernet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43my_train_stim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mx_train_stim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43my_val_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mx_val_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43my_val_stim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[43mx_val_stim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr_step_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlr_gamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43msequence_length_LSTM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 29\u001b[0m, in \u001b[0;36mtrain_hypernet\u001b[0;34m(model, hnet, y_train_base, x_train_base, y_train_stim, x_train_stim, y_val_base, x_val_base, y_val_stim, x_val_stim, lr, lr_step_size, lr_gamma, sequence_length_LSTM, batch_size_train, batch_size_val, num_epochs, delta, regularizer, l1_ratio, alpha, early_stop, chunks)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_hypernet\u001b[39m(model, hnet,y_train_base, x_train_base,\n\u001b[1;32m      2\u001b[0m                 y_train_stim,  x_train_stim,\n\u001b[1;32m      3\u001b[0m                 y_val_base,  x_val_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# --> this was only when using th models from hypnettorch\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"     if chunks:\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m         hnet.apply_chunked_hyperfan_init(mnet = model)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    else: \u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m         hnet.apply_hyperfan_init(mnet=model) \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mhnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_hyperfan_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Set up the optimizer with the specified learning rate\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(hnet\u001b[38;5;241m.\u001b[39minternal_params, lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[0;32m~/anaconda3/envs/sinthlab/lib/python3.8/site-packages/hypnettorch/hnets/mlp_hnet.py:551\u001b[0m, in \u001b[0;36mHMLP.apply_hyperfan_init\u001b[0;34m(self, method, use_xavier, uncond_var, cond_var, mnet, w_val, w_var, b_val, b_var)\u001b[0m\n\u001b[1;32m    549\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mnet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mnet, MainNetInterface)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m         meta \u001b[38;5;241m=\u001b[39m mnet\u001b[38;5;241m.\u001b[39mparam_shapes_meta\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_losses, val_losses, W_base, W_stim = train_hypernet(model, hnet,y_train_base, x_train_base,\n",
    "                y_train_stim,  x_train_stim,\n",
    "                y_val_base,  x_val_base,\n",
    "                y_val_stim,    x_val_stim,\n",
    "                lr=0.0001,\n",
    "                lr_step_size=10,\n",
    "                lr_gamma=0.9,\n",
    "                sequence_length_LSTM=15,\n",
    "                batch_size_train = 5,\n",
    "                batch_size_val = 5,\n",
    "                num_epochs=1000, \n",
    "                delta = 8,                 \n",
    "                regularizer=None,\n",
    "                l1_ratio = 0.5,\n",
    "                alpha = 1e-5,     \n",
    "                early_stop = 5,\n",
    "                chunks = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_losses and val_losses are numpy arrays containing losses for each epoch\n",
    "plot_losses(t_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_explained_variance(x, y, mnet):\n",
    "    \"\"\"Compute the explained variance for a given dataset\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Process complete dataset as one batch.\n",
    "        # Convert X_train and y_train to PyTorch tensors\n",
    "        inputs = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "        targets = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "\n",
    "        # Forward pass to get predictions\n",
    "        predictions = mnet(inputs)\n",
    "\n",
    "        y_array = targets.detach().cpu().numpy()\n",
    "        y_pred_array = predictions.detach().cpu().numpy()\n",
    "     \n",
    "        # Reshape tensors to 2D arrays (flatten the batch and sequence dimensions)\n",
    "        y_pred_2D = y_pred_array.reshape(-1, y_pred_array.shape[-1])\n",
    "        y_true_2D = y_array.reshape(-1, y_array.shape[-1])\n",
    "\n",
    "        # Compute explained variance\n",
    "        explained_var = r2_score(y_true_2D, y_pred_2D)\n",
    "\n",
    "    return explained_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = ['Training', 'Validation', 'Test']\n",
    "\n",
    "data_base = [[x_train_base, y_train_base],\n",
    "             [x_val_base, y_val_base],\n",
    "             [x_test_base, y_test_base]]\n",
    "\n",
    "data_stim = [[x_train_stim, y_train_stim],\n",
    "             [x_val_stim, y_val_stim],\n",
    "             [x_test_stim, y_test_stim]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance for  Training  is :  -1.5990448532477342\n",
      "Explained variance for  Validation  is :  -0.5150845599717658\n",
      "Explained variance for  Test  is :  -1.022689295875334\n"
     ]
    }
   ],
   "source": [
    "for index, [x,y] in enumerate(data_base):\n",
    "    ev = calc_explained_variance(x, y, model)\n",
    "    print('Explained variance for ', subsets[index], ' is : ', ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance for  Training  is :  -1.9380712869097536\n",
      "Explained variance for  Validation  is :  -0.8536884339811207\n",
      "Explained variance for  Test  is :  -1.1597706395312246\n"
     ]
    }
   ],
   "source": [
    "for index, [x,y] in enumerate(data_stim):\n",
    "    ev = calc_explained_variance(x, y, model)\n",
    "    print('Explained variance for ', subsets[index], ' is : ', ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sinthlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
