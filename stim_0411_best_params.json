{"n_hidden_units": 29, "num_layers": 4, "input_size_LSTM": 31, "dropout_1": 0.8345976574442866, "dropout_2": 0.6125416027383583, "lr": 0.0019300357710035122, "lr_gamma": 1.4370057715432787, "seq_length_LSTM": 6, "batch_size_train": 23, "batch_size_val": 49, "huber_delta": 8, "alpha_reg": 1.2105872414087716e-06, "l1_ratio_reg": 0.39395238042273817}